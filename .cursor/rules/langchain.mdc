---
description: LangChain RAG 코드 작성 규칙
globs: ["**/indexer.py", "**/retriever.py", "**/generator.py", "**/chain*.py"]
---

# LangChain 컨벤션 (1.0+)

## LCEL (LangChain Expression Language) 패턴

RAG 체인은 LCEL 파이프라인 문법 사용:

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

def format_docs(docs: list[Document]) -> str:
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

## 임포트 규칙

- `langchain_core`: 핵심 추상화 (Document, Runnable 등)
- `langchain_community`: 커뮤니티 통합 (로더 등)
- `langchain_openai`: OpenAI 통합
- `langchain_huggingface`: HuggingFace 통합
- `langchain_qdrant`: Qdrant 통합

```python
# Good - 구체적인 패키지에서 임포트
from langchain_openai import ChatOpenAI
from langchain_qdrant import QdrantVectorStore

# Bad - langchain에서 직접 임포트 (deprecated)
from langchain.chat_models import ChatOpenAI
```

## 벡터 스토어

```python
# 검색기 생성
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 5}
)

# 직접 검색
docs = vectorstore.similarity_search(query, k=5)
docs_with_scores = vectorstore.similarity_search_with_score(query, k=5)
```

## 프롬프트 템플릿

```python
prompt = ChatPromptTemplate.from_template("""
컨텍스트를 기반으로 질문에 답변하세요.

Context:
{context}

Question: {question}

Answer:""")
```

## 비동기 지원

- `.invoke()` → 동기 실행
- `.ainvoke()` → 비동기 실행
- FastAPI에서는 `ainvoke()` 사용 권장
