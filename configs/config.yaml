# LabQ RAG 서비스 설정

embedding:
  model_name: "BAAI/bge-m3"
  device: "cpu"
  normalize: true

splitter:
  chunk_size: 1000
  chunk_overlap: 200

retriever:
  top_k: 5
  search_type: "similarity"

qdrant:
  collection_name: "labq_docs"
  host: "${QDRANT_HOST:-localhost}"  # Docker: qdrant, 로컬: localhost
  port: 6333
  timeout: 5  # 초

llm:
  # 지원 프로바이더: openai, google_genai, anthropic
  provider: "google_genai"
  # model: "gemini-3-flash-preview"  # 미지정 시 프로바이더별 기본값 사용
  temperature: 0.0
  timeout: 30  # 초

  # 프로바이더별 기본 모델 (참고용)
  # openai: gpt-4o-mini
  # google_genai: gemini-3-flash-preview
  # anthropic: claude-3-5-haiku-latest
